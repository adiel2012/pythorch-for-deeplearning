{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": "<a href=\"https://colab.research.google.com/github/adiel2012/pythorch-for-deeplearning/blob/main/notebooks/01_fundamental_tensor_operations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# Chapter 1: Fundamental Tensor Operations\n",
    "\n",
    "This notebook covers the fundamentals of PyTorch tensors - the building blocks of deep learning.\n",
    "\n",
    "## Learning Objectives\n",
    "- Create tensors using various methods\n",
    "- Understand tensor properties and manipulation\n",
    "- Perform basic tensor operations\n",
    "- Work with different tensor shapes and dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "# Install PyTorch if not already available\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "except ImportError:\n",
    "    !pip install torch torchvision torchaudio\n",
    "    import torch\n",
    "    print(f\"PyTorch installed. Version: {torch.__version__}\")\n",
    "\n",
    "# Import necessary libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "creating_tensors"
   },
   "source": [
    "## 1. Creating Tensors\n",
    "\n",
    "Let's explore different ways to create tensors in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tensor_creation"
   },
   "outputs": [],
   "source": [
    "# Create tensors from Python lists\n",
    "tensor_from_list = torch.tensor([1, 2, 3, 4, 5])\n",
    "print(f\"From list: {tensor_from_list}\")\n",
    "print(f\"Shape: {tensor_from_list.shape}\")\n",
    "print(f\"Data type: {tensor_from_list.dtype}\")\n",
    "\n",
    "# Create 2D tensor\n",
    "tensor_2d = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(f\"\\n2D tensor:\\n{tensor_2d}\")\n",
    "print(f\"Shape: {tensor_2d.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tensor_creation_methods"
   },
   "outputs": [],
   "source": [
    "# Various tensor creation methods\n",
    "print(\"=== Tensor Creation Methods ===\")\n",
    "\n",
    "# Zeros and ones\n",
    "zeros_tensor = torch.zeros(3, 4)\n",
    "ones_tensor = torch.ones(2, 3)\n",
    "print(f\"Zeros (3x4):\\n{zeros_tensor}\")\n",
    "print(f\"\\nOnes (2x3):\\n{ones_tensor}\")\n",
    "\n",
    "# Random tensors\n",
    "random_tensor = torch.randn(2, 3)  # Normal distribution\n",
    "uniform_tensor = torch.rand(2, 3)  # Uniform [0, 1)\n",
    "print(f\"\\nRandom normal (2x3):\\n{random_tensor}\")\n",
    "print(f\"\\nRandom uniform (2x3):\\n{uniform_tensor}\")\n",
    "\n",
    "# Range tensors\n",
    "arange_tensor = torch.arange(0, 10, 2)\n",
    "linspace_tensor = torch.linspace(0, 1, 5)\n",
    "print(f\"\\nArange (0 to 10, step 2): {arange_tensor}\")\n",
    "print(f\"Linspace (0 to 1, 5 points): {linspace_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tensor_properties"
   },
   "source": [
    "## 2. Tensor Properties and Manipulation\n",
    "\n",
    "Understanding tensor properties is crucial for deep learning operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "properties"
   },
   "outputs": [],
   "source": [
    "# Create a sample tensor\n",
    "sample_tensor = torch.randn(2, 3, 4)\n",
    "\n",
    "print(\"=== Tensor Properties ===\")\n",
    "print(f\"Tensor: {sample_tensor.shape}\")\n",
    "print(f\"Shape: {sample_tensor.shape}\")\n",
    "print(f\"Size: {sample_tensor.size()}\")\n",
    "print(f\"Number of dimensions: {sample_tensor.ndim}\")\n",
    "print(f\"Number of elements: {sample_tensor.numel()}\")\n",
    "print(f\"Data type: {sample_tensor.dtype}\")\n",
    "print(f\"Device: {sample_tensor.device}\")\n",
    "print(f\"Requires gradient: {sample_tensor.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "reshaping"
   },
   "outputs": [],
   "source": [
    "# Tensor reshaping operations\n",
    "print(\"=== Tensor Reshaping ===\")\n",
    "\n",
    "# Original tensor\n",
    "x = torch.arange(12)\n",
    "print(f\"Original: {x}\")\n",
    "print(f\"Shape: {x.shape}\")\n",
    "\n",
    "# Reshape to 2D\n",
    "x_2d = x.reshape(3, 4)\n",
    "print(f\"\\nReshaped to 3x4:\\n{x_2d}\")\n",
    "\n",
    "# Reshape to 3D\n",
    "x_3d = x.reshape(2, 2, 3)\n",
    "print(f\"\\nReshaped to 2x2x3:\\n{x_3d}\")\n",
    "\n",
    "# Using view (similar to reshape but with memory sharing)\n",
    "x_view = x.view(4, 3)\n",
    "print(f\"\\nView as 4x3:\\n{x_view}\")\n",
    "\n",
    "# Squeeze and unsqueeze\n",
    "x_unsqueezed = x.unsqueeze(0)  # Add dimension at index 0\n",
    "print(f\"\\nUnsqueezed shape: {x_unsqueezed.shape}\")\n",
    "\n",
    "x_squeezed = x_unsqueezed.squeeze(0)  # Remove dimension at index 0\n",
    "print(f\"Squeezed back shape: {x_squeezed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "indexing_slicing"
   },
   "source": [
    "## 3. Indexing and Slicing\n",
    "\n",
    "Learn how to access and modify tensor elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "indexing"
   },
   "outputs": [],
   "source": [
    "# Create a 3D tensor for indexing examples\n",
    "tensor_3d = torch.arange(24).reshape(2, 3, 4)\n",
    "print(f\"3D Tensor (2x3x4):\\n{tensor_3d}\")\n",
    "\n",
    "print(\"\\n=== Indexing Examples ===\")\n",
    "# Basic indexing\n",
    "print(f\"First matrix (index 0):\\n{tensor_3d[0]}\")\n",
    "print(f\"Element at [0, 1, 2]: {tensor_3d[0, 1, 2]}\")\n",
    "print(f\"First row of first matrix: {tensor_3d[0, 0, :]}\")\n",
    "print(f\"First column of all matrices: {tensor_3d[:, :, 0]}\")\n",
    "\n",
    "# Slicing\n",
    "print(f\"\\nSlice [0, :2, 1:3]:\\n{tensor_3d[0, :2, 1:3]}\")\n",
    "\n",
    "# Boolean indexing\n",
    "mask = tensor_3d > 10\n",
    "print(f\"\\nElements > 10: {tensor_3d[mask]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "basic_operations"
   },
   "source": [
    "## 4. Basic Tensor Operations\n",
    "\n",
    "Perform mathematical operations on tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "arithmetic"
   },
   "outputs": [],
   "source": [
    "# Basic arithmetic operations\n",
    "a = torch.tensor([1, 2, 3, 4])\n",
    "b = torch.tensor([5, 6, 7, 8])\n",
    "\n",
    "print(\"=== Arithmetic Operations ===\")\n",
    "print(f\"a = {a}\")\n",
    "print(f\"b = {b}\")\n",
    "\n",
    "# Element-wise operations\n",
    "print(f\"\\nAddition: {a + b}\")\n",
    "print(f\"Subtraction: {a - b}\")\n",
    "print(f\"Multiplication: {a * b}\")\n",
    "print(f\"Division: {a / b}\")\n",
    "print(f\"Power: {a ** 2}\")\n",
    "\n",
    "# In-place operations\n",
    "a_copy = a.clone()\n",
    "a_copy.add_(5)  # Add 5 to all elements in-place\n",
    "print(f\"\\nAfter in-place addition of 5: {a_copy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "advanced_operations"
   },
   "outputs": [],
   "source": [
    "# Matrix operations\n",
    "print(\"=== Matrix Operations ===\")\n",
    "\n",
    "# Create matrices\n",
    "A = torch.randn(3, 4)\n",
    "B = torch.randn(4, 2)\n",
    "\n",
    "print(f\"Matrix A (3x4):\\n{A}\")\n",
    "print(f\"\\nMatrix B (4x2):\\n{B}\")\n",
    "\n",
    "# Matrix multiplication\n",
    "C = torch.matmul(A, B)  # or A @ B\n",
    "print(f\"\\nMatrix multiplication A @ B (3x2):\\n{C}\")\n",
    "\n",
    "# Transpose\n",
    "A_T = A.T  # or A.transpose(0, 1)\n",
    "print(f\"\\nTranspose of A (4x3):\\n{A_T}\")\n",
    "\n",
    "# Dot product for vectors\n",
    "v1 = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "v2 = torch.tensor([4, 5, 6], dtype=torch.float32)\n",
    "dot_product = torch.dot(v1, v2)\n",
    "print(f\"\\nDot product of {v1} and {v2}: {dot_product}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "broadcasting"
   },
   "source": [
    "## 5. Broadcasting\n",
    "\n",
    "Understanding how PyTorch handles operations between tensors of different shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "broadcasting_examples"
   },
   "outputs": [],
   "source": [
    "print(\"=== Broadcasting Examples ===\")\n",
    "\n",
    "# Scalar with tensor\n",
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "scalar = 10\n",
    "result = tensor + scalar\n",
    "print(f\"Tensor (2x3):\\n{tensor}\")\n",
    "print(f\"Scalar: {scalar}\")\n",
    "print(f\"Result:\\n{result}\")\n",
    "\n",
    "# Vector with matrix\n",
    "matrix = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "vector = torch.tensor([10, 20, 30])\n",
    "result = matrix + vector\n",
    "print(f\"\\nMatrix (2x3):\\n{matrix}\")\n",
    "print(f\"Vector (3,): {vector}\")\n",
    "print(f\"Broadcasted result:\\n{result}\")\n",
    "\n",
    "# Different broadcasting scenarios\n",
    "a = torch.randn(3, 1, 4)\n",
    "b = torch.randn(1, 2, 1)\n",
    "result = a + b\n",
    "print(f\"\\nShape a: {a.shape}\")\n",
    "print(f\"Shape b: {b.shape}\")\n",
    "print(f\"Broadcasted result shape: {result.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aggregation"
   },
   "source": [
    "## 6. Aggregation Operations\n",
    "\n",
    "Learn reduction operations like sum, mean, max, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aggregations"
   },
   "outputs": [],
   "source": [
    "# Create sample tensor\n",
    "data = torch.randn(3, 4)\n",
    "print(f\"Sample tensor (3x4):\\n{data}\")\n",
    "\n",
    "print(\"\\n=== Aggregation Operations ===\")\n",
    "# Basic aggregations\n",
    "print(f\"Sum of all elements: {data.sum()}\")\n",
    "print(f\"Mean of all elements: {data.mean()}\")\n",
    "print(f\"Standard deviation: {data.std()}\")\n",
    "print(f\"Maximum value: {data.max()}\")\n",
    "print(f\"Minimum value: {data.min()}\")\n",
    "\n",
    "# Aggregation along specific dimensions\n",
    "print(f\"\\nSum along rows (dim=0): {data.sum(dim=0)}\")\n",
    "print(f\"Sum along columns (dim=1): {data.sum(dim=1)}\")\n",
    "print(f\"Mean along rows: {data.mean(dim=0)}\")\n",
    "print(f\"Max along columns: {data.max(dim=1)}\")\n",
    "\n",
    "# Argmax and argmin\n",
    "print(f\"\\nArgmax (flattened): {data.argmax()}\")\n",
    "print(f\"Argmax along columns: {data.argmax(dim=1)}\")\n",
    "print(f\"Argmin along rows: {data.argmin(dim=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exercises"
   },
   "source": [
    "## 7. Practice Exercises\n",
    "\n",
    "Try these exercises to test your understanding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "exercise1"
   },
   "outputs": [],
   "source": [
    "# Exercise 1: Create a 5x5 identity matrix\n",
    "print(\"Exercise 1: Create a 5x5 identity matrix\")\n",
    "identity = torch.eye(5)\n",
    "print(identity)\n",
    "\n",
    "# Verify it's an identity matrix\n",
    "print(f\"\\nVerification - diagonal elements: {identity.diag()}\")\n",
    "print(f\"Sum of off-diagonal elements: {identity.sum() - identity.diag().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "exercise2"
   },
   "outputs": [],
   "source": [
    "# Exercise 2: Create a tensor with values from 1 to 20, reshape it to 4x5\n",
    "print(\"Exercise 2: Create and reshape tensor\")\n",
    "tensor = torch.arange(1, 21).reshape(4, 5)\n",
    "print(f\"Tensor (4x5):\\n{tensor}\")\n",
    "\n",
    "# Find elements greater than 10\n",
    "mask = tensor > 10\n",
    "print(f\"\\nElements > 10: {tensor[mask]}\")\n",
    "print(f\"Count of elements > 10: {mask.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "exercise3"
   },
   "outputs": [],
   "source": [
    "# Exercise 3: Matrix operations\n",
    "print(\"Exercise 3: Matrix operations\")\n",
    "\n",
    "# Create two random matrices\n",
    "torch.manual_seed(42)\n",
    "A = torch.randn(3, 3)\n",
    "B = torch.randn(3, 3)\n",
    "\n",
    "print(f\"Matrix A:\\n{A}\")\n",
    "print(f\"\\nMatrix B:\\n{B}\")\n",
    "\n",
    "# Compute A * B and B * A\n",
    "AB = A @ B\n",
    "BA = B @ A\n",
    "\n",
    "print(f\"\\nA @ B:\\n{AB}\")\n",
    "print(f\"\\nB @ A:\\n{BA}\")\n",
    "\n",
    "# Check if matrix multiplication is commutative\n",
    "is_commutative = torch.allclose(AB, BA)\n",
    "print(f\"\\nIs matrix multiplication commutative? {is_commutative}\")\n",
    "print(f\"Difference (A@B - B@A):\\n{AB - BA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualization"
   },
   "source": [
    "## 8. Visualization\n",
    "\n",
    "Let's visualize some tensor operations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize_tensors"
   },
   "outputs": [],
   "source": [
    "# Create sample data for visualization\n",
    "x = torch.linspace(-5, 5, 100)\n",
    "y1 = torch.sin(x)\n",
    "y2 = torch.cos(x)\n",
    "y3 = torch.tanh(x)\n",
    "\n",
    "# Plot using matplotlib\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x.numpy(), y1.numpy(), label='sin(x)', linewidth=2)\n",
    "plt.plot(x.numpy(), y2.numpy(), label='cos(x)', linewidth=2)\n",
    "plt.plot(x.numpy(), y3.numpy(), label='tanh(x)', linewidth=2)\n",
    "plt.title('Mathematical Functions with PyTorch')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Visualize a 2D tensor as heatmap\n",
    "plt.subplot(1, 2, 2)\n",
    "random_matrix = torch.randn(8, 8)\n",
    "plt.imshow(random_matrix.numpy(), cmap='viridis', aspect='auto')\n",
    "plt.title('2D Tensor Visualization')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Matrix shape: {random_matrix.shape}\")\n",
    "print(f\"Matrix mean: {random_matrix.mean():.4f}\")\n",
    "print(f\"Matrix std: {random_matrix.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary"
   },
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we covered:\n",
    "\n",
    "1. **Tensor Creation**: Multiple ways to create tensors from scratch\n",
    "2. **Properties**: Understanding tensor shape, dtype, device, etc.\n",
    "3. **Manipulation**: Reshaping, indexing, and slicing tensors\n",
    "4. **Operations**: Arithmetic and matrix operations\n",
    "5. **Broadcasting**: How PyTorch handles different tensor shapes\n",
    "6. **Aggregation**: Reduction operations like sum, mean, max\n",
    "7. **Exercises**: Hands-on practice with tensor operations\n",
    "8. **Visualization**: Plotting tensor data\n",
    "\n",
    "These fundamental operations form the foundation for all deep learning operations in PyTorch!\n",
    "\n",
    "### Next Steps\n",
    "- Practice with different tensor shapes and operations\n",
    "- Explore GPU operations by moving tensors to CUDA device\n",
    "- Try creating your own tensor manipulation functions\n",
    "- Move on to the next notebook: Mathematical Operations"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM...",
   "collapsed_sections": [],
   "name": "01_fundamental_tensor_operations.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}